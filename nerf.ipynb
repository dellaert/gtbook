{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: nerf.html\n",
    "description: Support Code for Neural Radiance Fields\n",
    "title: nerf\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp nerf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# | exporti\n",
    "WHITE = torch.full((3,), 1.0, dtype=torch.float)\n",
    "DEVICE = (\n",
    "    torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Radiance Fields\n",
    "\n",
    "Most of the code is defined in the book as well, but here we more thoroughly test it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from Rays\n",
    "\n",
    "Given a point $P$ on the ray at a distance $t$ from the origin $O$, in the direction $D$ is given as\n",
    "\n",
    "$$\n",
    "P(t,O,D) = O + t  D\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_along_ray(t_values, origins, directions):\n",
    "    \"\"\"Sample points along rays defined by origins and (unit-norm) directions.\"\"\"\n",
    "    return origins[..., None, :] + t_values[:, None] * directions[..., None, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the way we implemented `sample_along_ray` takes care to handle *arbitrary* batches of origin/direction pairs, as long as their last dimensions is 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_values = torch.tensor([1, 2, 3, 4, 5])\n",
    "origins = torch.tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n",
    "directions = torch.tensor([[1.0, 0.0, 0.0], [1.0/ np.sqrt(2), 1.0/ np.sqrt(2), 0.0]])\n",
    "\n",
    "samples = sample_along_ray(t_values, origins, directions)\n",
    "\n",
    "test_eq(samples.shape, torch.Size([2, 5, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line above asserts that we sampled 2 rays for 5 different $t$-values, each of them being 3-dimensional points as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration along Rays\n",
    "\n",
    "Assuming that we are given the densities $\\sigma_i$ and colors $c_i$ at $N$ sampled points $P_i$ on a ray corresponding to a given pixel, then we can calculate the color for the ray using the equation below,\n",
    "\n",
    "$$\n",
    "C = \\sum_{i=1}^N T_i \\alpha_i c_i\n",
    "$$\n",
    "\n",
    "where $T_i$ is the **transmittance**:\n",
    "\n",
    "$$\n",
    "T_i \\doteq \\exp ( - \\sum_{j=1}^{i-1} \\sigma_j)\n",
    "$$\n",
    "\n",
    "The transmittance $T_i$ measures the *lack* of occlusion in the space between the $i^th$ sample and the ray origin. The quantity $\\alpha_i$, on the other hand, is the alpha value or **opacity** at the $i^th$ sample, defined as\n",
    "\n",
    "$$\n",
    "\\alpha_i \\doteq 1 - \\exp(-\\sigma_i).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_along_ray(density, rgb, background=WHITE):\n",
    "    \"\"\"Compute the final rendered color given the density and RGB values.\"\"\"\n",
    "    alpha = 1 - torch.exp(-density)\n",
    "    cumulative_density = torch.cumsum(density, dim=-1)\n",
    "    trans = torch.exp(-cumulative_density)\n",
    "    trans = torch.cat([torch.ones_like(density[..., :1]), trans[..., :-1]], dim=-1)\n",
    "    \n",
    "    weights = alpha * trans\n",
    "    color_acc = torch.einsum('...i,...ij->...j', weights, rgb)\n",
    "    acc = weights.sum(dim=-1, keepdim=True)\n",
    "\n",
    "    return color_acc + (1.0 - acc) * background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test using randomly generated `density` and `rgb` inputs that have the same shape as our sampled rays from above, asserting that we indeed get *two* RGB colors as the end-result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7174011  0.6973155  0.4935117 ]\n",
      " [0.7510586  0.77856576 0.30422565]]\n"
     ]
    }
   ],
   "source": [
    "density = torch.rand(2, 5) # Random density\n",
    "rgb = torch.rand(2, 5, 3) # Random colors (between 0 and 1)\n",
    "rendered = render_along_ray(density, rgb)\n",
    "test_eq( rendered.shape, torch.Size([2, 3]))\n",
    "print(rendered.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Differentiable Voxel Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(v0, v1, alpha):\n",
    "    \"\"\"Interpolate between v0 and v1 using alpha, using unsqueeze to properly handle batches.\"\"\"\n",
    "    return v0 * (1 - alpha.unsqueeze(-1)) + v1 * alpha.unsqueeze(-1)\n",
    "\n",
    "class VoxelGrid(nn.Module):\n",
    "    def __init__(self, shape, d=1, max=1.0):\n",
    "        \"\"\"A 3D voxel grid with given `shape` with learnable values at the corners of the voxels.\"\"\"\n",
    "        super(VoxelGrid, self).__init__()\n",
    "        self.grid = nn.Parameter(torch.rand(*shape, d) * max)\n",
    "\n",
    "\n",
    "    def forward(self, P):\n",
    "        \"\"\"Implement trilinear interpolation at the points P.\"\"\"\n",
    "        x, y, z = P[..., 0], P[..., 1], P[..., 2]\n",
    "\n",
    "        # Get indices of the corners, clamping to the grid size where needed:\n",
    "        X0, Y0, Z0 = torch.floor(x).long(), torch.floor(y).long(), torch.floor(z).long()\n",
    "        X1 = torch.clamp(X0 + 1, max=self.grid.shape[0] - 1)\n",
    "        Y1 = torch.clamp(Y0 + 1, max=self.grid.shape[1] - 1)\n",
    "        Z1 = torch.clamp(Z0 + 1, max=self.grid.shape[2] - 1)\n",
    "\n",
    "        # Get blending weights along each axis:\n",
    "        a, b, c = x - X0, y - Y0, z - Z0\n",
    "\n",
    "        # Interpolate in the x direction:\n",
    "        y0z0 = interpolate(self.grid[X0, Y0, Z0, :], self.grid[X1, Y0, Z0, :], a)\n",
    "        y1z0 = interpolate(self.grid[X0, Y1, Z0, :], self.grid[X1, Y1, Z0, :], a)\n",
    "        y0z1 = interpolate(self.grid[X0, Y0, Z1, :], self.grid[X1, Y0, Z1, :], a)\n",
    "        y1z1 = interpolate(self.grid[X0, Y1, Z1, :], self.grid[X1, Y1, Z1, :], a)\n",
    "\n",
    "        # Interpolate in the y direction:\n",
    "        z0 = interpolate(y0z0, y1z0, b)\n",
    "        z1 = interpolate(y0z1, y1z1, b)\n",
    "        \n",
    "        # Interpolate in the z direction:\n",
    "        return interpolate(z0, z1, c).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below initializes a VoxelGrid with random values, and then evaluates the a scalar function at a 3D point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated Output: 0.61790\n"
     ]
    }
   ],
   "source": [
    "voxel_grid_module = VoxelGrid(shape=(6, 6, 6), d=1)\n",
    "point = torch.Tensor([1.5, 2.7, 3.4])\n",
    "output = voxel_grid_module(point)\n",
    "print(f\"Interpolated Output: {output.item():.5f}\")\n",
    "test_eq(output.shape, torch.Size([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create a grid that interpolates a four-dimensional function (`d=4`), and evaluate it at a 2x2 batch `x` of 3D points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated Output:\n",
      " [[[0.50723857 0.5354987  0.6874882  0.47449723]\n",
      "  [0.38862017 0.43923682 0.55946934 0.5623423 ]]\n",
      "\n",
      " [[0.38862017 0.43923682 0.55946934 0.5623423 ]\n",
      "  [0.38862017 0.43923682 0.55946934 0.5623423 ]]]\n"
     ]
    }
   ],
   "source": [
    "voxel_grid_module = VoxelGrid(shape = (6, 6, 6), d=4)\n",
    "\n",
    "x = torch.Tensor([[[1.5, 2.7, 3.4], [2.3, 4.6, 1.1]], [[2.3, 4.6, 1.1], [2.3, 4.6, 1.1]]])\n",
    "y = voxel_grid_module(x)\n",
    "test_eq(x.shape, torch.Size([2, 2, 3]))\n",
    "test_eq(y.shape, torch.Size([2, 2, 4]))\n",
    "print(\"Interpolated Output:\\n\", y.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DVGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    near: float = 1.5\n",
    "    far: float = 3.5\n",
    "    num_samples: int = 64\n",
    "    min_corner: tuple[float] = (-1.0, -1.0, 0.0)\n",
    "    max_corner: tuple[float] = (1.0, 1.0, 1.0)\n",
    "    shape: tuple[int] = (128, 128, 128)\n",
    "    background = WHITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDVGO(nn.Module):\n",
    "    def __init__(self, config: Config = Config()):\n",
    "        \"\"\"Initialize voxel grids and bounding box corners.\"\"\"\n",
    "        super().__init__()  # Calling the superclass's __init__ method\n",
    "\n",
    "        # Initialize sampler parameters:\n",
    "        self.depths = torch.linspace(\n",
    "            config.near, config.far, config.num_samples + 1, dtype=torch.float32\n",
    "        )\n",
    "        self.t_values = 0.5 * (self.depths[1:] + self.depths[:-1])\n",
    "\n",
    "        # Set up conversion from scene coordinates to grid coordinates:\n",
    "        self.min_corner = torch.tensor(config.min_corner, dtype=torch.float32)\n",
    "        self.max_corner = torch.tensor(config.max_corner, dtype=torch.float32)\n",
    "        self.scale = 1.0 / (self.max_corner - self.min_corner)\n",
    "        self.float_shape = torch.tensor(config.shape, dtype=torch.float32)\n",
    "\n",
    "        # Initialize differentiable voxel grids:\n",
    "        self.rgb_voxel_grid = VoxelGrid(config.shape, d=3, max=1.0)\n",
    "        self.density_voxel_grid = VoxelGrid(config.shape, d=1, max=0.1)\n",
    "\n",
    "        # Finally, record background color for rendering:\n",
    "        self.background = config.background\n",
    "\n",
    "    def forward(self, x_samples):\n",
    "        \"\"\"Perform volume rendering using the provided ray information.\"\"\"\n",
    "        # Extract ray origins and directions from x_samples\n",
    "        origins = x_samples[..., :3].to(dtype=torch.float32)\n",
    "        directions = x_samples[..., 3:].to(dtype=torch.float32)\n",
    "\n",
    "        # Sample along the ray\n",
    "        samples = sample_along_ray(self.t_values, origins, directions)\n",
    "\n",
    "        # Rescale to fit within the grid\n",
    "        unclamped = (samples - self.min_corner) * self.scale\n",
    "        rescaled = torch.clamp(unclamped, 0.0, 0.9999999) * self.float_shape\n",
    "\n",
    "        # Query Density Voxel Grid\n",
    "        density = F.softplus(torch.squeeze(self.density_voxel_grid(rescaled)))\n",
    "        sparsity_penalty = torch.sum(torch.abs(density))\n",
    "\n",
    "        # Query RGB Voxel Grid\n",
    "        rgb = torch.sigmoid(self.rgb_voxel_grid(rescaled))\n",
    "\n",
    "        # Render\n",
    "        return render_along_ray(density, rgb, self.background), sparsity_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we calculate the colors for 32 random rays, each with their origin and direction stacked into a 6-vector, so the input batch size is $32 \\times 6$, and we expect an output batch size of RGB colors, i.e., $32 \\times 3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity_penalty: 131.33258056640625\n"
     ]
    }
   ],
   "source": [
    "# Initialize renderer\n",
    "dvgo = SimpleDVGO()\n",
    "\n",
    "x_samples = torch.rand((32, 6))\n",
    "y_samples, sparsity_penalty = dvgo(x_samples)\n",
    "# Verify shape of the output\n",
    "test_eq(y_samples.shape, torch.Size([32, 3]))\n",
    "test_eq(sparsity_penalty.shape, torch.Size([]))\n",
    "print(\"sparsity_penalty:\", sparsity_penalty.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
